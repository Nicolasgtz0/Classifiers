#Loading Python Packages 
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from scipy.io import arff
from sklearn.ensemble import RandomForestClassifier

#Load and check the data 
df = pd.read_csv('credit_risk_dataset.csv')   
list(df)
df.head()

#Process the data to make it easier to model (Lowercase all the variables and change to numeric variables)
df = df.apply(lambda x: x.astype(str).str.lower())
df = df.replace('y', 1)
df = df.replace('n', 0)

#Subset the Dataset
list(df)
xVar = df
yVar = df.iloc[:,1] 
df2 = df
#df2 = df.drop(["person_home_ownership", "loan_intent","loan_grade"], axis = 1, inplace=True)
df2 = df2.reset_index()
df2.dropna(inplace=True)

#Split the data in train and test sets 
X_train, X_test, y_train, y_test = train_test_split(df2, yVar, test_size=0.2)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)
# In the code above, the data is split in a way that 80% of the variables fall under the training set and 20% of the 
#variables are used for testing the model. Our resulting training set has 26064 observations and the 
# testing set has 6517 observations.

print(len(y_train))
y_train = y_train.dropna()
print(len(y_train))

#Building Random Forest Model 
# I will try to fix it as soon as possible, I will also try with XGBoost instead of RF

clf = RandomForestClassifier(n_jobs=2, random_state=0)

clf.fit(X_train, y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=10, n_jobs=2, oob_score=False, random_state=0,
            verbose=0, warm_start=False)

# Predict the model 
preds = clf.predict(X_test)

# Evaluate predictor 

#Import scikit-learn metrics module for accuracy calculation
from sklearn import metrics
# How often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, preds))
pd.crosstab(y_test, preds, rownames=['Actual Result'], colnames=['Predicted Result'])

# How important are our features ? 
list(zip(X_train, clf.feature_importances_)) 

